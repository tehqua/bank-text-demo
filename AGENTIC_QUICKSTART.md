# Agentic AI Quick Start Guide

## Giá»›i thiá»‡u nhanh

Há»‡ thá»‘ng Agentic AI cá»§a chÃºng tÃ´i bao gá»“m **7 agents tá»± chá»§** lÃ m viá»‡c cÃ¹ng nhau Ä‘á»ƒ cáº£i tiáº¿n liÃªn tá»¥c cÃ¡c models machine learning.

### 7 Agents chÃ­nh:

1. **ModelCardAgent** - Quáº£n lÃ½ metadata vÃ  performance cá»§a models
2. **LearningAgent** - Äiá»u phá»‘i continuous learning
3. **AutoTrainer** - Tá»± Ä‘á»™ng retrain models
4. **GoalManager** - Theo dÃµi KPIs vÃ  goals
5. **Monitor** - PhÃ¡t hiá»‡n anomalies vÃ  drift
6. **Planner** - Táº¡o action plans
7. **Executor** - Thá»±c thi actions

## CÃ¡ch sá»­ dá»¥ng trong Streamlit App

### BÆ°á»›c 1: Upload vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u

1. VÃ o tab **"Upload & Analyze"**
2. Upload file CSV (pháº£i cÃ³ cá»™t `comment`)
3. Click **"Run Analysis"**

### BÆ°á»›c 2: Khá»Ÿi Ä‘á»™ng Agentic AI System

1. VÃ o tab **"ğŸ¤– True Agentic AI - Multi-Agent System"**
2. Há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng initialize 7 agents
3. Báº¡n sáº½ tháº¥y: âœ… Multi-Agent System initialized with 7 agents

### BÆ°á»›c 3: Cháº¡y Autonomous Workflow

Click **"Run Full Agentic Workflow"** Ä‘á»ƒ:
- LÆ°u baseline metrics
- Kiá»ƒm tra goal violations
- PhÃ¡t hiá»‡n anomalies
- Táº¡o vÃ  thá»±c thi action plans
- Cháº¡y learning cycle (náº¿u Ä‘áº¿n lÃºc)
- Review táº¥t cáº£ model cards

### BÆ°á»›c 4: Trigger Continuous Improvement

Click **"Trigger Continuous Improvement"** Ä‘á»ƒ:
- Cháº¡y learning cycle ngay láº­p tá»©c
- Process training queue
- Identify uncertain samples cáº§n label
- Update performance baselines

### BÆ°á»›c 5: Xem System Status

Click **"Get System Status"** Ä‘á»ƒ xem:
- Sá»‘ lÆ°á»£ng active agents
- Tá»•ng sá»‘ model cards
- Learning status (last cycle, next cycle)
- Recent improvements

### BÆ°á»›c 6: Monitor Agent Communications

- **View Agent Messages**: Xem messages giá»¯a cÃ¡c agents
- **View Coordination History**: Xem lá»‹ch sá»­ coordination actions

### BÆ°á»›c 7: Xem Model Cards

Click **"View All Model Cards"** Ä‘á»ƒ xem:
- Táº¥t cáº£ models Ä‘Ã£ Ä‘Æ°á»£c train
- Performance metrics (accuracy, F1, etc.)
- Status vÃ  deployment info

## TÃ­nh nÄƒng tá»± Ä‘á»™ng

### 1. Auto-Detection Performance Degradation

Khi model accuracy giáº£m > 10%:
```
ModelCardAgent phÃ¡t hiá»‡n â†’ publish event
  â†“
AutoTrainer nháº­n event â†’ thÃªm vÃ o training queue
  â†“
LearningAgent trigger immediate cycle
  â†“
Model Ä‘Æ°á»£c retrain tá»± Ä‘á»™ng
```

### 2. Continuous Learning Cycle (24h)

Má»—i 24 giá», há»‡ thá»‘ng tá»± Ä‘á»™ng:
- Kiá»ƒm tra training queue
- Process pending training tasks
- Identify uncertain predictions
- Update baselines

### 3. Active Learning

Há»‡ thá»‘ng tá»± Ä‘á»™ng tÃ¬m predictions khÃ´ng cháº¯c cháº¯n:
- Confidence < 70% â†’ mark as uncertain
- Sáº¯p xáº¿p theo uncertainty score
- Gá»£i Ã½ top samples cáº§n human labeling

## Workflow Ä‘iá»ƒn hÃ¬nh

### Workflow 1: First Time Setup

```
1. Upload data â†’ Run Analysis
2. VÃ o tab Agentic AI
3. Run Full Agentic Workflow
4. System creates baseline vÃ  model cards
```

### Workflow 2: Daily Monitoring

```
1. Upload new data â†’ Run Analysis
2. Run Full Agentic Workflow
3. System detects violations/anomalies
4. Auto-creates vÃ  executes action plans
```

### Workflow 3: Manual Improvement

```
1. Trigger Continuous Improvement
2. Xem uncertain samples
3. Label uncertain samples (trong tab Edit & Export)
4. Upload labeled data â†’ Train model
5. System auto-creates new model card
```

### Workflow 4: Model Performance Tracking

```
1. View All Model Cards
2. Xem performance history
3. So sÃ¡nh models qua cÃ¡c versions
4. Identify models cáº§n retrain
```

## VÃ­ dá»¥ cá»¥ thá»ƒ

### VÃ­ dá»¥ 1: PhÃ¡t hiá»‡n vÃ  xá»­ lÃ½ Negative Spike

```
Scenario: Äá»™t ngá»™t cÃ³ nhiá»u comments tiÃªu cá»±c

1. Upload data â†’ Run Analysis
2. Run Full Agentic Workflow

Há»‡ thá»‘ng tá»± Ä‘á»™ng:
âœ“ Monitor detects negative spike (+15%)
âœ“ GoalManager identifies violation (threshold: 10%)
âœ“ Planner creates action: "alert_ops"
âœ“ Executor sends alert (email/slack)
âœ“ Learning cycle triggered Ä‘á»ƒ retrain model
```

### VÃ­ dá»¥ 2: Model Accuracy giáº£m

```
Scenario: Sentiment model accuracy tá»« 0.92 â†’ 0.78

Há»‡ thá»‘ng tá»± Ä‘á»™ng:
âœ“ ModelCardAgent detects degradation
âœ“ Publishes: model.degradation_detected
âœ“ AutoTrainer adds to queue
âœ“ LearningAgent triggers immediate cycle
âœ“ Model Ä‘Æ°á»£c retrain vá»›i data má»›i
âœ“ New model card Ä‘Æ°á»£c táº¡o
âœ“ Performance comparison available
```

### VÃ­ dá»¥ 3: Continuous Improvement vá»›i Active Learning

```
1. Run Analysis â†’ 1000 comments
2. System predicts sentiment
3. Active Learning identifies 50 uncertain samples
4. Trong tab "Edit & Export":
   - Filter by sentiment_score < 0.7
   - Review vÃ  edit labels
   - Export labeled data
5. Trong tab "Training":
   - Upload labeled CSV
   - Train Sentiment Model
6. System auto-creates model card
7. LearningAgent updates baseline
```

## Message Bus Events

### Events báº¡n cÃ³ thá»ƒ monitor:

- `model.trained` - Model vá»«a Ä‘Æ°á»£c train xong
- `model.degradation_detected` - Performance giáº£m
- `learning.cycle_completed` - Learning cycle hoÃ n thÃ nh
- `goals.violations_detected` - KPI violations
- `monitor.anomalies_detected` - Anomalies phÃ¡t hiá»‡n
- `training.queued` - Training task added

### Xem message history:

```python
# Trong code
coordinator = st.session_state.coordinator
messages = coordinator.get_agent_communications(limit=20)
```

## Tuning vÃ  Configuration

### Thay Ä‘á»•i Learning Cycle Interval

```python
# Default: 24 hours
# Thay Ä‘á»•i thÃ nh 12 hours:
coordinator.learning_agent.configure_learning_interval(hours=12)
```

### Thay Ä‘á»•i Active Learning Threshold

```python
# Default: 0.3 (samples vá»›i confidence < 0.7)
# Thay Ä‘á»•i thÃ nh 0.2 (confidence < 0.8):
coordinator.learning_agent.active_learner.uncertainty_threshold = 0.2
```

### Thay Ä‘á»•i Minimum Training Samples

```python
# Default: 10 samples
# Thay Ä‘á»•i thÃ nh 20:
coordinator.learning_agent.auto_trainer.min_samples_for_training = 20
```

### Thay Ä‘á»•i Goals/KPIs

```python
# Trong GoalManager
new_goals = {
    "sentiment_accuracy": {
        "metric": "sentiment_accuracy",
        "threshold": 0.85,  # Thay tá»« 0.7 â†’ 0.85
        "operator": ">=",
        "priority": "high",
        "action": "retrain_sentiment"
    }
}

coordinator.goal_manager.goals.update(new_goals)
coordinator.goal_manager.save_goals()
```

## Troubleshooting

### âŒ Agents khÃ´ng communicate

**Kiá»ƒm tra:**
```python
coordinator = st.session_state.coordinator
messages = coordinator.get_agent_communications(limit=10)
print(f"Messages: {len(messages)}")
```

**Giáº£i phÃ¡p:** Re-initialize coordinator
```python
st.session_state.coordinator = None
# Refresh page
```

### âŒ Learning cycle khÃ´ng trigger

**Kiá»ƒm tra:**
```python
status = coordinator.learning_agent.get_learning_status()
print(status['next_cycle_in'])
```

**Giáº£i phÃ¡p:** Force trigger
```python
coordinator.trigger_continuous_improvement(df)
```

### âŒ Training queue khÃ´ng process

**Kiá»ƒm tra:**
```python
stats = coordinator.learning_agent.auto_trainer.get_training_statistics()
print(f"Queue: {stats['queue_size']}")
```

**Giáº£i phÃ¡p:** Manual process
```python
results = coordinator.learning_agent.auto_trainer.process_training_queue(df)
```

## Best Practices

### 1. Äá»‹nh ká»³ cháº¡y Full Workflow

- Má»—i ngÃ y: Run Full Agentic Workflow
- Xem violations vÃ  anomalies
- Review action plans trÆ°á»›c khi execute

### 2. Monitor Model Cards

- Weekly: Xem all model cards
- Compare performance trends
- Identify models cáº§n attention

### 3. Active Learning Strategy

- Export uncertain samples
- Batch labeling (20-50 samples/láº§n)
- Retrain khi Ä‘á»§ labeled data

### 4. Baseline Updates

- Update baseline sau major changes
- Monthly baseline refresh
- Keep history for comparison

### 5. Goal Tuning

- Review goals quarterly
- Adjust thresholds dá»±a trÃªn business needs
- Add new goals khi cáº§n

## FAQs

**Q: Bao lÃ¢u learning cycle cháº¡y 1 láº§n?**
A: Default lÃ  24 giá», cÃ³ thá»ƒ configure.

**Q: Agents cÃ³ cáº§n internet khÃ´ng?**
A: KhÃ´ng, toÃ n bá»™ cháº¡y local.

**Q: Model Cards lÆ°u á»Ÿ Ä‘Ã¢u?**
A: `models/cards/*.json`

**Q: CÃ³ thá»ƒ táº¯t auto-training khÃ´ng?**
A: CÃ³, Ä‘á»«ng click "Trigger Continuous Improvement". System sáº½ chá»‰ suggest actions.

**Q: Message history lÆ°u bao lÃ¢u?**
A: Message history in-memory, máº¥t khi restart app. CÃ³ thá»ƒ extend Ä‘á»ƒ persist.

**Q: CÃ³ thá»ƒ add thÃªm agents khÃ´ng?**
A: CÃ³, táº¡o class má»›i extend tá»« base agent, subscribe vÃ o message bus.

---

**Tip:** Báº¯t Ä‘áº§u Ä‘Æ¡n giáº£n vá»›i Run Full Agentic Workflow, sau Ä‘Ã³ explore tá»«ng feature!
