# H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t Ollama cho AI Chatbot

## Ollama l√† g√¨?

Ollama cho ph√©p ch·∫°y Large Language Models (LLMs) nh∆∞ Llama, Mistral, v.v. **ho√†n to√†n FREE** v√† **LOCAL** tr√™n m√°y t√≠nh c·ªßa b·∫°n.

## B∆∞·ªõc 1: C√†i ƒë·∫∑t Ollama

### Windows:

1. Download Ollama t·ª´: https://ollama.com/download
2. Ch·∫°y file installer `OllamaSetup.exe`
3. Ollama s·∫Ω t·ª± ƒë·ªông kh·ªüi ƒë·ªông v√† ch·∫°y trong background

### macOS:

```bash
brew install ollama
```

### Linux:

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

## B∆∞·ªõc 2: Pull model

M·ªü terminal/command prompt v√† ch·∫°y:

```bash
ollama pull llama3.2:3b
```

**C√°c model kh√°c b·∫°n c√≥ th·ªÉ d√πng:**
- `llama3.2:3b` - Nh·∫π, nhanh (3GB RAM) - **Khuy√™n d√πng**
- `llama3.2:1b` - R·∫•t nh·∫π (1GB RAM) - Cho m√°y y·∫øu
- `gemma2:2b` - Alternative (2GB RAM)
- `llama3.1:8b` - M·∫°nh h∆°n (8GB RAM) - N·∫øu m√°y kh·ªèe

## B∆∞·ªõc 3: Ki·ªÉm tra Ollama ƒëang ch·∫°y

```bash
ollama list
```

B·∫°n s·∫Ω th·∫•y danh s√°ch models ƒë√£ pull.

Ho·∫∑c test chat:
```bash
ollama run llama3.2:3b
```

Nh·∫≠p "xin ch√†o" ƒë·ªÉ test ‚Üí Ctrl+D ƒë·ªÉ tho√°t

## B∆∞·ªõc 4: Ch·∫°y Chatbot trong App

```bash
cd C:\Users\PC\bank-text-demo
streamlit run app.py
```

V√†o tab **üí¨ AI Chatbot** v√† b·∫Øt ƒë·∫ßu chat!

## Troubleshooting

### L·ªói: "Ollama kh√¥ng kh·∫£ d·ª•ng"

**Solution 1:** Ki·ªÉm tra Ollama ƒëang ch·∫°y
```bash
# Windows
tasklist | findstr ollama

# Linux/macOS
ps aux | grep ollama
```

**Solution 2:** Start Ollama manually
```bash
ollama serve
```

**Solution 3:** Ki·ªÉm tra port 11434
```bash
curl http://localhost:11434/api/tags
```

### L·ªói: Model qu√° ch·∫≠m

- D√πng model nh·ªè h∆°n: `ollama pull llama3.2:1b`
- Update app.py ƒë·ªÉ d√πng model m·ªõi:
  ```python
  ChatbotAgent(df_pandas, model="llama3.2:1b")
  ```

### L·ªói: Out of memory

- Close c√°c app kh√°c
- D√πng model 1B ho·∫∑c 2B
- TƒÉng RAM n·∫øu c√≥ th·ªÉ

## T√≠nh nƒÉng Chatbot

**Chatbot c√≥ th·ªÉ:**
- ‚úÖ Truy v·∫•n data: "Cho t√¥i th·ªëng k√™ t·ªïng quan"
- ‚úÖ T√¨m issues: "Top 5 v·∫•n ƒë·ªÅ ti√™u c·ª±c l√† g√¨?"
- ‚úÖ Check anomalies: "Ki·ªÉm tra anomalies"
- ‚úÖ L·ªçc data: "C√≥ bao nhi√™u comment v·ªÅ chuy·ªÉn ti·ªÅn?"
- ‚úÖ Qu·∫£n l√Ω models: "X√≥a topic models"

**V√≠ d·ª• conversation:**

```
User: Cho t√¥i th·ªëng k√™ t·ªïng quan
AI: üìä Summary Statistics:
    - Total comments: 100
    - Unique topics: 8
    - Average sentiment: -0.5
    - Negative comments: 45 (45%)

User: Top 3 v·∫•n ƒë·ªÅ ti√™u c·ª±c l√† g√¨?
AI: üö® Top 3 Negative Issues:
    1. Topic: Transfer Issues | Sentiment: Very Negative
       Comment: Chuy·ªÉn ti·ªÅn b·ªã l·ªói...
    2. Topic: App Performance | Sentiment: Negative
       Comment: App lag gi·∫≠t...
    ...

User: Ki·ªÉm tra anomalies
AI: ‚ö†Ô∏è Detected 2 anomalies:
    - sentiment_drift: Sentiment distribution drift detected: 0.234
    - negative_spike: Negative sentiment spike: +15%
```

## Thay ƒë·ªïi model trong code

M·ªü `app.py`, t√¨m d√≤ng:
```python
st.session_state.chatbot_agent = ChatbotAgent(st.session_state.df_pandas)
```

S·ª≠a th√†nh:
```python
st.session_state.chatbot_agent = ChatbotAgent(st.session_state.df_pandas, model="llama3.2:1b")
```

## Resources

- Ollama docs: https://ollama.com/docs
- Model library: https://ollama.com/library
- GitHub: https://github.com/ollama/ollama
